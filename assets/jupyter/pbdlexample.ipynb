{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2edba268-ac82-4b67-aa2a-e9bd6e423a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 33.23193359375\n",
      "Epoch 100, Loss: 0.0010111266747117043\n",
      "Epoch 200, Loss: 0.0002765950048342347\n",
      "Epoch 300, Loss: 9.012725058710203e-05\n",
      "Epoch 400, Loss: 1.9460174371488392e-05\n",
      "Epoch 500, Loss: 3.5050049973506248e-06\n",
      "Epoch 600, Loss: 1.844927510319394e-06\n",
      "Epoch 700, Loss: 1.7233555809070822e-06\n",
      "Epoch 800, Loss: 1.7036819599525188e-06\n",
      "Epoch 900, Loss: 1.6891971199584077e-06\n",
      "Predicted acceleration for F=5: 2.500002861022949\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()        # Activation function\n",
    "        self.fc2 = nn.Linear(10, 1)  # Hidden layer to output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simulated training data\n",
    "F_data = torch.rand(100, 1) * 10  # Force values between 0 and 10\n",
    "A_data = F_data / 2               # a = F/m, with m = 2\n",
    "\n",
    "# Training the network with physics-informed loss\n",
    "lambda_reg = 1.0  # Regularization parameter\n",
    "\n",
    "for epoch in range(1000):  # Training for 1000 epochs\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    A_pred = model(F_data)\n",
    "    \n",
    "    # Data-driven loss (mean squared error)\n",
    "    loss_data = criterion(A_pred, A_data)\n",
    "    \n",
    "    # Physics-informed loss (F = 2 * a)\n",
    "    physics_loss = criterion(F_data, 2 * A_pred)\n",
    "    \n",
    "    # Total loss\n",
    "    loss = loss_data + lambda_reg * physics_loss\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_F = torch.tensor([[5.0]])  # Example test input\n",
    "    test_A_pred = model(test_F)\n",
    "    print(f'Predicted acceleration for F=5: {test_A_pred.item()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
