---
---

@string{aps = {American Physical Society,}}

@book{einstein1920relativity,
  title={Relativity: the Special and General Theory},
  author={Einstein, Albert},
  year={1920},
  publisher={Methuen & Co Ltd},
  html={relativity.html}
}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif},
  abbr={Vision}
}

@article{GREN2019112,
  abbr={Elsevier},
title = {Calculating the costs of animal-vehicle accidents involving ungulate in Sweden},
journal = {Transportation Research Part D: Transport and Environment},
volume = {70},
pages = {112-122},
year = {2019},
issn = {1361-9209},
doi = {https://doi.org/10.1016/j.trd.2019.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S1361920918305856},
  html={https://www.sciencedirect.com/science/article/abs/pii/S1361920918305856},
author = {Ing-Marie Gren and Annika Jägerbrand},
keywords = {Costs, Traffic accidents, Ungulates, Population dynamics, Econometrics, Sweden},
abstract = {Animal-vehicle collisions (AVCs) involving ungulate species pose a serious problem in many countries, and the prediction of accidents and costs on a regional and national spatial scale is important for efficient accident mitigation. Based on the assumption that AVCs are determined by traffic volume and ungulate population dynamics, this study developed a relatively simple method for calculating and predicting the costs of current and future traffic accidents involving moose, roe deer and wild boar in Sweden. A logistic population model was assumed for all three ungulate species and econometric methods were applied to obtain population growth models based on panel data on traffic accidents, traffic load, hunting bags, hunting licenses and landscape characteristics for each Swedish county and year from 2003 to 2015. The population growth models were used to predict vehicle accidents and costs. The predicted annual discounted costs of AVCs over a 15-year period based on projected ungulate populations and traffic volume fell by 25\% from 406 million USD in 2015, however the allocation of costs between ungulates differed. AVCs involving roe deer accounted for the largest share of the costs (54\%), but collisions involving wild boar showed the most rapid increase over the study period because of a relatively high estimated growth rate and recent expansion of wild boar populations to several new counties. However, the predicted costs were sensitive to assumptions regarding population dynamics as well as assumptions about future hunting pressure and traffic volume.}
}

@InProceedings{10.1007/978-3-031-62281-6_30,
  abbr={Springer},
author="Russo, Vincenzo
and Barra, Paola
and Tortora, Augusto
and Russo, Guido
and Battistoni, Pietro
and Sebillo, Monica
and Tortora, Genoveffa",
editor="Arai, Kohei",
title="Wild Animal Recognition Using an Edge Device",
booktitle="Intelligent Computing",
year="2024",
publisher="Springer Nature Switzerland",
address="Cham",
pages="415--432",
  html={https://link.springer.com/chapter/10.1007/978-3-031-62281-6_30},
abstract="Neural networks and deep learning are in rapid development; new technologies and increasingly high-performance computing centres allow operations to be carried out that, until a few years ago, were impossible due to excessive processing times. The possibility of exploiting an Edge/Cloud configuration allows speed in training neural networks, ability to operate in real-time, elasticity, and resistance of the entire system in the event of a failure. This configuration helps reduce costs by using less expensive tools in the sensing and edge regions. In this work, an edge computing system was implemented to recognise wild animals such as goats and wild boars. The image recognition problem was therefore addressed by exploiting transfer learning techniques on two state-of-the-art methods: YOLOv5 and EfficientNet. The comparison of the results highlighted the pros and cons of the two methods.",
isbn="978-3-031-62281-6"
}


@Article{su142214859,
AUTHOR = {ElSahly, Osama and Abdelfatah, Akmal},
TITLE = {A Systematic Review of Traffic Incident Detection Algorithms},
JOURNAL = {Sustainability},
VOLUME = {14},
YEAR = {2022},
NUMBER = {22},
ARTICLE-NUMBER = {14859},
URL = {https://www.mdpi.com/2071-1050/14/22/14859},
  html={https://www.mdpi.com/2071-1050/14/22/14859},
ISSN = {2071-1050},
ABSTRACT = {Traffic incidents have negative impacts on traffic flow and the gross domestic product of most countries. In addition, they may result in fatalities and injuries. Thus, efficient incident detection systems have a vital role in restoring normal traffic conditions on the roads and saving lives and properties. Researchers have realized the importance of Automatic Incident Detection (AID) systems and conducted several studies to develop AID systems to quickly detect traffic incidents with an acceptable performance level. An incident detection system mainly consists of two modules: a data collection module and a data processing module. The performance of AID systems is assessed using three performance measures; Detection Rate (DR), False Alarm Rate (FAR) and Mean Time to Detect (MTTD). Based on data processing and incident detection algorithms, AID can be categorized into four categories: comparative, statistical, artificial intelligence-based and video–image processing algorithms. The aim of this paper is to investigate and summarize the existing AID systems by assessing their performance, strengths, limitations and their corresponding data collection and data processing techniques. This is useful in highlighting the shortcomings of these systems and providing potential solutions that future research should focus on. The literature is sought through an extensive review of the existing refereed publications using the Google Scholar search engine and Scopus database. The methodology adopted for this research is a systematic literature review following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. This study can serve as a reference for researchers who are interested in developing new AID systems.},
DOI = {10.3390/su142214859}
}

@inproceedings{10.1145/1378600.1378605,
author = {Eriksson, Jakob and Girod, Lewis and Hull, Bret and Newton, Ryan and Madden, Samuel and Balakrishnan, Hari},
title = {The pothole patrol: using a mobile sensor network for road surface monitoring},
year = {2008},
isbn = {9781605581392},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1378600.1378605},
html={https://dl.acm.org/doi/abs/10.1145/1378600.1378605},
doi = {10.1145/1378600.1378605},
abstract = {This paper investigates an application of mobile sensing: detecting and reporting the surface conditions of roads. We describe a system and associated algorithms to monitor this important civil infrastructure using a collection of sensor-equipped vehicles. This system, which we call the Pothole Patrol (P2), uses the inherent mobility of the participating vehicles, opportunistically gathering data from vibration and GPS sensors, and processing the data to assess road surface conditions. We have deployed P2 on 7 taxis running in the Boston area. Using a simple machine-learning approach, we show that we are able to identify potholes and other severe road surface anomalies from accelerometer data. Via careful selection of training data and signal features, we have been able to build a detector that misidentifies good road segments as having potholes less than 0.2\% of the time. We evaluate our system on data from thousands of kilometers of taxi drives, and show that it can successfully detect a number of real potholes in and around the Boston area. After clustering to further reduce spurious detections, manual inspection of reported potholes shows that over 90\% contain road anomalies in need of repair.},
booktitle = {Proceedings of the 6th International Conference on Mobile Systems, Applications, and Services},
pages = {29–39},
numpages = {11},
keywords = {mobile sensing, road surface monitoring},
location = {Breckenridge, CO, USA},
series = {MobiSys '08}
}
@inproceedings{abou2018municipal,
  title={Municipal infrastructure anomaly and defect detection},
  author={Abou Chacra, David and Zelek, John},
  booktitle={2018 26th European Signal Processing Conference (EUSIPCO)},
  pdf = {https://www.eurasip.org/Proceedings/Eusipco/Eusipco2018/papers/1570437793.pdf},
  pages={2125--2129},
  year={2018},
  organization={IEEE}
}


@Article{vehicles5030051,
AUTHOR = {Ruseruka, Cuthbert and Mwakalonge, Judith and Comert, Gurcan and Siuhi, Saidi and Perkins, Judy},
TITLE = {Road Condition Monitoring Using Vehicle Built-in Cameras and GPS Sensors: A Deep Learning Approach},
JOURNAL = {Vehicles},
VOLUME = {5},
YEAR = {2023},
NUMBER = {3},
PAGES = {931--948},
URL = {https://www.mdpi.com/2624-8921/5/3/51},
ISSN = {2624-8921},
ABSTRACT = {Road authorities worldwide can leverage the advances in vehicle technology by continuously monitoring their roads’ conditions to minimize road maintenance costs. The existing methods for carrying out road condition surveys involve manual observations using standard survey forms, performed by qualified personnel. These methods are expensive, time-consuming, infrequent, and can hardly provide real-time information. Some automated approaches also exist but are very expensive since they require special vehicles equipped with computing devices and sensors for data collection and processing. This research aims to leverage the advances in vehicle technology in providing a cheap and real-time approach to carry out road condition monitoring (RCM). This study developed a deep learning model using the You Only Look Once, Version 5 (YOLOv5) algorithm that was trained to capture and categorize flexible pavement distresses (FPD) and reached 95\% precision, 93.4\% recall, and 97.2\% mean Average Precision. Using vehicle built-in cameras and GPS sensors, these distresses were detected, images were captured, and locations were recorded. This was validated on campus roads and parking lots using a car featured with a built-in camera and GPS. The vehicles’ built-in technologies provided a more cost-effective and efficient road condition monitoring approach that could also provide real-time road conditions.},
DOI = {10.3390/vehicles5030051}
}

@INPROCEEDINGS {Arnab9710415,
author = {A. Arnab and M. Dehghani and G. Heigold and C. Sun and M. Lucic and C. Schmid},
booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
title = {ViViT: A Video Vision Transformer},
year = {2021},
pages = {6816-6826},
abstract = {We present pure-transformer based models for video classification, drawing upon the recent success of such models in image classification. Our model extracts spatiotemporal tokens from the input video, which are then encoded by a series of transformer layers. In order to handle the long sequences of tokens encountered in video, we propose several, efficient variants of our model which factorise the spatial- and temporal-dimensions of the input. Although transformer-based models are known to only be effective when large training datasets are available, we show how we can effectively regularise the model during training and leverage pretrained image models to be able to train on comparatively small datasets. We conduct thorough ablation studies, and achieve state-of-the-art results on multiple video classification benchmarks including Kinetics 400 and 600, Epic Kitchens, Something-Something v2 and Moments in Time, outperforming prior methods based on deep 3D convolutional networks.},
keywords = {training;computer vision;three-dimensional displays;benchmark testing;transformers;spatiotemporal phenomena;kinetic theory},
doi = {10.1109/ICCV48922.2021.00676},
url = {https://doi.ieeecomputersociety.org/10.1109/ICCV48922.2021.00676},
html={https://ieeexplore.ieee.org/abstract/document/9710415},
  pdf = {https://openaccess.thecvf.com/content/ICCV2021/papers/Arnab_ViViT_A_Video_Vision_Transformer_ICCV_2021_paper.pdf},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {oct}
}

@article{VANRUITENBEEK2022100332,
title = {Convolutional Neural Networks for vehicle damage detection},
journal = {Machine Learning with Applications},
volume = {9},
pages = {100332},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2022.100332},
url = {https://www.sciencedirect.com/science/article/pii/S2666827022000433},
html = {https://www.sciencedirect.com/science/article/pii/S2666827022000433},
author = {R.E. {van Ruitenbeek} and S. Bhulai},
keywords = {Computer vision, Image recognition, Object detection, Deep learning, Vehicle damage detection},
abstract = {Vehicle damages are increasingly becoming a liability for shared mobility services. The large number of handovers between drivers demands for an accurate and fast inspection system, which locates small damages and classifies these into the correct damage category. To address this, a damage detection model is developed to locate vehicle damages and classify these into twelve categories. Multiple deep learning algorithms are used, and the effect of different transfer learning and training strategies is evaluated, to optimize the detection performance. The final model, trained on more than 10,000 damage images, is able to accurately detect small damages under various conditions such as water and dirt. A performance evaluation with domain experts shows, that the model achieves comparable performance. In addition, the model is evaluated in a specially designed light street, indicating that strong reflections complicate the detection performance.}
}

@ARTICLE{Mallios10194904,
  author={Mallios, Dimitrios and Xiaofei, Li and McLaughlin, Niall and Rincon, Jesus Martinez Del and Galbraith, Clare and Garland, Rory},
  journal={IEEE Access}, 
  title={Vehicle Damage Severity Estimation for Insurance Operations Using In-The-Wild Mobile Images}, 
  year={2023},
  volume={11},
  number={},
  pages={78644-78655},
  html={https://ieeexplore.ieee.org/abstract/document/10194904},
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10194904},
  keywords={Estimation;Insurance;Costs;Feature extraction;Computational modeling;Computer vision;Deep learning;Accidents;Automobiles;Claim operations;insurance;vehicle damage estimation;computer-vision;deep-learning},
  doi={10.1109/ACCESS.2023.3299223}}
  
  @article{arikan2019surface,
  title={Surface defect classification in real-time using convolutional neural networks},
  author={Arikan, Selim and Varanasi, Kiran and Stricker, Didier},
  journal={arXiv preprint arXiv:1904.04671},
    html={https://arxiv.org/abs/1904.04671},
  pdf={https://arxiv.org/pdf/1904.04671},
  year={2019}
}


@Article{jimaging9100193,
AUTHOR = {Cumbajin, Esteban and Rodrigues, Nuno and Costa, Paulo and Miragaia, Rolando and Frazão, Luís and Costa, Nuno and Fernández-Caballero, Antonio and Carneiro, Jorge and Buruberri, Leire H. and Pereira, António},
TITLE = {A Systematic Review on Deep Learning with CNNs Applied to Surface Defect Detection},
JOURNAL = {Journal of Imaging},
VOLUME = {9},
YEAR = {2023},
NUMBER = {10},
ARTICLE-NUMBER = {193},
URL = {https://www.mdpi.com/2313-433X/9/10/193},
html= {https://www.mdpi.com/2313-433X/9/10/193},
PubMedID = {37888300},
ISSN = {2313-433X},
ABSTRACT = {Surface defect detection with machine learning has become an important tool in industries and a large field of study for researchers or workers in recent years. It is necessary to have a simplified source of information that helps us to better focus on one type of surface. In this systematic review, we present a classification for surface defect detection based on convolutional neural networks (CNNs) focused on surface types. Findings: Out of 253 records identified, 59 primary studies were eligible. Following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, we analyzed the structures of each study and the concepts related to defects and their types on surfaces. The presented review is mainly focused on finding a classification for the types of surfaces most used in industry (metal, building, ceramic, wood, and special). We delve into the specifics of each surface category, offering illustrative examples of their applications within both industrial and laboratory settings. Furthermore, we propose a new taxonomy of machine learning based on the obtained results and collected information. We summarized the studies and extracted the main characteristics such as type of surface, problem types, timeline, type of network, techniques, and datasets. Among the most relevant results of our analysis, we found that the metallic surface is the most used, as it is the one found in 62.71\% of the studies, and the most prevalent problem type is classification, accounting for 49.15\% of the total. Furthermore, we observe that transfer learning was employed in 83.05\% of the studies, while data augmentation was utilized in 59.32\%. Our findings also provide insights into the cameras most frequently employed, along with the strategies adopted to address illumination challenges present in certain articles and the approach to creating datasets for real-world applications. The main results presented in this review allow for a quick and efficient search of information for researchers and professionals interested in improving the results of their defect detection projects. Finally, we analyzed the trends that could open new fields of study for future research in the area of surface defect detection.},
DOI = {10.3390/jimaging9100193}
}

@ARTICLE{Gholami10477550,
  author={Gholami, Amir and Yao, Zhewei and Kim, Sehoon and Hooper, Coleman and Mahoney, Michael W. and Keutzer, Kurt},
  journal={IEEE Micro}, 
  title={AI and Memory Wall}, 
  year={2024},
  volume={44},
  number={3},
  pages={33-39},
  html= {https://ieeexplore.ieee.org/abstract/document/10477550},
  pdf = {https://arxiv.org/pdf/2403.14123},
  keywords={Computational modeling;Training data;Transformers;Bandwidth;Arithmetic;Hardware;Data models;Unsupervised learning;Artificial intelligence;Memory management},
  abstract ={The availability of unprecedented unsupervised training data, along with neural scaling laws, has resulted in an unprecedented surge in model size and compute requirements for serving/training large language models. However, the main performance bottleneck is increasingly shifting to memory bandwidth. Over the past 20 years, peak server hardware floating-point operations per second have been scaling at 3.0 times per two years, outpacing the growth of dynamic random-access memory and interconnect bandwidth, which have only scaled at 1.6 and 1.4 times every two years, respectively. This disparity has made memory, rather than compute, the primary bottleneck in AI applications, particularly in serving. Here, we analyze encoder and decoder transformer models and show how memory bandwidth can become the dominant bottleneck for decoder models. We argue for a redesign in model architecture, training, and deployment strategies to overcome this memory limitation.},
  doi={10.1109/MM.2024.3373763}}
  
  @book{thuerey:hal-04083995,
  TITLE = {{Physics-based Deep Learning}},
  AUTHOR = {Thuerey, Nils and Holl, Philipp and Mueller, Maximilian and Schnell, Patrick and Trost, Felix and Um, Kiwon},
  URL = {https://telecom-paris.hal.science/hal-04083995},
  pdf={https://arxiv.org/pdf/2109.05237},
  abstract = {This digital book contains a practical and comprehensive introduction of everything related to deep learning in the context of physical simulations. As much as possible, all topics come with hands-on code examples in the form of Jupyter notebooks to quickly get started. Beyond standard supervised learning from data, we'll look at physical loss constraints, more tightly coupled learning algorithms with differentiable simulations, as well as reinforcement learning and uncertainty modeling. We live in exciting times: these methods have a huge potential to fundamentally change what computer simulations can achieve.},
  NOTE = {PBDL v0.2, available online at: https://www.physicsbaseddeeplearning.org/},
  YEAR = {2021},
  MONTH = Sep,
  DOI = {10.48550/arXiv.2109.05237},
  HAL_ID = {hal-04083995},
  HAL_VERSION = {v1},
}

@ARTICLE{Thompson9563954,
  author={Thompson, Neil C. and Greenewald, Kristjan and Lee, Keeheon and Manso, Gabriel F.},
  journal={IEEE Spectrum}, 
  title={Deep Learning's Diminishing Returns: The Cost of Improvement is Becoming Unsustainable}, 
  year={2021},
  volume={58},
  number={10},
  pages={50-55},
    html= {https://ieeexplore.ieee.org/document/9563954},
abstract = {Deep learning is now being used to translate between languages, predict how proteins fold, analyze medical scans, and play games as complex as Go, to name just a few applications of a technique that is now becoming pervasive. Success in those and other realms has brought this machine-learning technique from obscurity in the early 2000s to dominance today. • Although deep learning's rise to fame is relatively recent, its origins are not. In 1958, back when mainframe computers filled rooms and ran on vacuum tubes, knowledge of the interconnections between neurons in the brain inspired Frank Rosenblatt at Cornell to design the first artificial neural network, which he presciently described as a “pattern-recognizing device.” But Rosenblatt's ambitions outpaced the capabilities of his era—and he knew it. Even his inaugural paper was forced to acknowledge the voracious appetite of neural networks for computational power, bemoaning that “as the number of connections in the network increases…the burden on a conventional digital computer soon becomes excessive.” • Fortunately for such artificial neural networks—later rechristened “deep learning” when they included extra layers of neurons—decades of Moore's Law and other improvements in computer hardware yielded a roughly 10-million-fold increase in the number of computations that a computer could do in a second. So when researchers returned to deep learning in the late 2000s, they wielded tools equal to the challenge.},
  keywords={Deep learning;Semiconductor device modeling;Proteins;Knowledge engineering;Moore's Law;Neurons;Tools},
  doi={10.1109/MSPEC.2021.9563954}}

@Article{proceedings2020047009,
AUTHOR = {Leijnen, Stefan and Veen, Fjodor van},
TITLE = {The Neural Network Zoo},
JOURNAL = {Proceedings},
VOLUME = {47},
YEAR = {2020},
NUMBER = {1},
ARTICLE-NUMBER = {9},
URL = {https://www.mdpi.com/2504-3900/47/1/9},
html = {https://www.mdpi.com/2504-3900/47/1/9},
pdf = {https://www.researchgate.net/publication/341373030_The_Neural_Network_Zoo},
ISSN = {2504-3900},
ABSTRACT = {An overview of neural network architectures is presented. Some of these architectures have been created in recent years, whereas others originate from many decades ago. Apart from providing a practical tool for comparing deep learning models, the Neural Network Zoo also uncovers a taxonomy of network architectures, their chronology, and traces back lineages and inspirations for these neural information processing systems.},
DOI = {10.3390/proceedings2020047009}
}

@article{Krizhevsky10.1145/3065386,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet classification with deep convolutional neural networks},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {60},
number = {6},
issn = {0001-0782},
url = {https://doi.org/10.1145/3065386},
doi = {10.1145/3065386},
html={https://dl.acm.org/doi/10.1145/3065386},
pdf = {https://dl.acm.org/doi/pdf/10.1145/3065386},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
journal = {Commun. ACM},
month = {may},
pages = {84–90},
numpages = {7}
}

@online{Hao2019,
  author       = {Karen Hao},
  title        = {Training a single AI model can emit as much carbon as five cars in their lifetimes},
  year         = 2019,
  url          = {https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/},
  urldate      = {2024-08-15},
  journal      = {MIT Technology Review},
  html={https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/},
  abstract={The artificial-intelligence industry is often compared to the oil industry: once mined and refined, data, like oil, can be a highly lucrative commodity. Now it seems the metaphor may extend even further. Like its fossil-fuel counterpart, the process of deep learning has an outsize environmental impact.}
}

@article{Strubell_Ganesh_McCallum_2020, 
title={Energy and Policy Considerations for Modern Deep Learning Research}, 
author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew}, 
year={2020}, 
month={Apr.}, 
volume={34}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/7123}, 
DOI={10.1609/aaai.v34i09.7123}, 
abstract={The field of artificial intelligence has experienced a dramatic methodological shift towards large neural networks trained on plentiful data. This shift has been fueled by recent advances in hardware and techniques enabling remarkable levels of computation, resulting in impressive advances in AI across many applications. However, the massive computation required to obtain these exciting results is costly both financially, due to the price of specialized hardware and electricity or cloud compute time, and to the environment, as a result of non-renewable energy used to fuel modern tensor processing hardware. In a paper published this year at ACL, we brought this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training and tuning neural network models for NLP (Strubell, Ganesh, and McCallum 2019). In this extended abstract, we briefly summarize our findings in NLP, incorporating updated estimates and broader information from recent related publications, and provide actionable recommendations to reduce costs and improve equity in the machine learning and artificial intelligence community}, 
number={09}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
pages={13693-13696}, 
html={https://arxiv.org/abs/1906.02243}, 
pdf={https://arxiv.org/pdf/1906.02243} 
}

@InProceedings{10.1007/978-3-030-93135-3_2,
author="Mazzara, Manuel
and Farina, Mirko
and Krylov{\'a}, Ad{\'e}la
and Semenova, Elizaveta
and Mohamed, Mosab",
editor="Succi, Giancarlo
and Ciancarini, Paolo
and Kruglov, Artem",
title="Software Engineering as an Alchemical Process: Establishing a Philosophy of the Discipline",
booktitle="Frontiers in Software Engineering",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="12--31",
abstract="Far from being a bizarre pastime, alchemy played a crucially important role in the history of science, being supported and promoted by leading political and scientific figures (such as Rudolf II, J{\={a}}bir ibn Hayy{\={a}}n, Gerard of Cremona, Adelard of Bath, Roger Bacon, Paracelsus, and even Newton). To understand alchemy, however, one has to approach it from both a material and a spiritual (perhaps philosophical) perspective. On the one hand, alchemists wanted to transform, or better transmute, materials (such as lead into gold). On the other hand, though, alchemists were also aiming at transforming qualities and aspects of themselves. In this paper, we show that Computer Science, and in particular Software Engineering, can be partly understood as alchemical processes. We thus draw analogies and specify points of contact between these two, prima facie, distinct and very distant worlds. In doing so, we also formulate and discuss a number of important questions regarding the nature and metaphysics of computation, that can be of interests to many researchers in computer science.",
isbn="978-3-030-93135-3"
}

@article{lecun2017my,
  title={My take on Ali Rahimi’s ‘Test of Time’ award talk at NIPS},
  author={LeCun, Yann},
  journal={Facebook, https://www. facebook. com/yann. lecun/posts/101 54938130592143},
  pages={06--12},
  year={2017},
  pdf = {https://www2.isye.gatech.edu/~tzhao80/Yann_Response.pdf},
}

@article{klinger2021deep,
  title={Deep learning, deep change? Mapping the evolution and geography of a general purpose technology},
  author={Klinger, Joel and Mateos-Garcia, Juan and Stathoulopoulos, Konstantinos},
  journal={Scientometrics},
  volume={126},
  pages={5589--5621},
  year={2021},
  publisher={Springer},
  html={https://link.springer.com/article/10.1007/s11192-021-03936-9}
}

@InProceedings{Redmon2016CVPR,
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
title = {You Only Look Once: Unified, Real-Time Object Detection},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
html = {https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html},
pdf = {https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf},
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
month = {June},
year = {2016}
}

@article{bochkovskiy2020yolov4,
  title={Yolov4: Optimal speed and accuracy of object detection},
  author={Bochkovskiy, Alexey and Wang, Chien-Yao and Liao, Hong-Yuan Mark},
  journal={arXiv preprint arXiv:2004.10934},
  abstract={There are a huge number of features which are said to improve Convolutional Neural Network (CNN) accuracy. Practical testing of combinations of such features on large datasets, and theoretical justification of the result, is required. Some features operate on certain models exclusively and for certain problems exclusively, or only for small-scale datasets; while some features, such as batch-normalization and residual-connections, are applicable to the majority of models, tasks, and datasets. We assume that such universal features include Weighted-Residual-Connections (WRC), Cross-Stage-Partial-connections (CSP), Cross mini-Batch Normalization (CmBN), Self-adversarial-training (SAT) and Mish-activation. We use new features: WRC, CSP, CmBN, SAT, Mish activation, Mosaic data augmentation, CmBN, DropBlock regularization, and CIoU loss, and combine some of them to achieve state-of-the-art results: 43.5\% AP (65.7\% AP50) for the MS COCO dataset at a realtime speed of ~65 FPS on Tesla V100.},
  pdf = {https://arxiv.org/pdf/2004.10934},
  year={2020}
}


@article{RAISSI2019686,
author = {M. Raissi and P. Perdikaris and G.E. Karniadakis},
title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
journal = {Journal of Computational Physics},
volume = {378},
pages = {686-707},
year = {2019},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
html= {https://www.sciencedirect.com/science/article/abs/pii/S0021999118307125},
pdf = {https://arxiv.org/pdf/1711.10561},
keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge–Kutta methods, Nonlinear dynamics},
abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.}
}

@article{BELANGER2023370,
title = {A Literature Review on Digital Twins in Warehouses},
journal = {Procedia Computer Science},
volume = {219},
pages = {370-377},
year = {2023},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN – International Conference on Project MANagement / HCist – International Conference on Health and Social Care Information Systems and Technologies 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.302},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923003113},
html = {https://www.sciencedirect.com/science/article/pii/S1877050923003113},
author = {Marie-Jane Bélanger and Robert Pellerin and Samir Lamouri},
keywords = {Review, Warehouse, Digital twin, Material Handling, Industry 4.0},
abstract = {Due to the high cost of their warehousing operations, many manufacturing companies are looking to increase the efficiency of their warehouse. To this end, Industry 4.0 technologies offer several solutions to address this issue. One of them is the digital twin (DT) technology which is relatively new. This paper presents a literature review on DTs in warehousing. The analysis framework used to classify the papers includes the general description of the DT, the possible uses, and the required data. Our results show that several limitations remain to exploit the full potential of a DT. The limitations mainly concern the characterization of the data required.}
}

